      <!DOCTYPE html>
	<html lang="en">
		<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
			<title>Power and 'fragile' p-values</title>
      	
         
         
            <meta name ="description" content ="What proportion of significant <i>p</i> values should be between 0.01 and 0.05? Turns out the answer is 'it depends'.">
            <meta property="og:description" content ="What proportion of significant <i>p</i> values should be between 0.01 and 0.05? Turns out the answer is 'it depends'.">
         
         <meta property="og:site_name" content="free range statistics" />
         <meta property="og:title" content="Power and 'fragile' p-values" />
         
            <meta property="og:image" content="https:/freerangestats.info/img/0295-fragile-diff.png" />
         
		 
			<meta property="og:url" content="https://freerangestats.info/blog/2025/06/08/power-and-fragile-p-values.html" />
		 
         <meta property="og:author" content= "https://www.facebook.com/peterstats" />
         <meta property="og:type" content="article" />
      

<link href='https://fonts.googleapis.com/css?family=Sarala' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Prosto+One' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet'>
	  
          <link href="/css/bootstrap.min.css" rel ="stylesheet" type="text/css">
          <link href="/css/bootstrap-theme.min.css" rel ="stylesheet" type="text/css">
            <link href="/css/custom.css" rel ="stylesheet" type="text/css">     
		<link href="/css/syntax.css" rel ="stylesheet" type="text/css">     			
                 
            
   <script>
     (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

     ga('create', 'UA-65886313-1', 'auto');
     ga('send', 'pageview');

   </script>
   
   <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



   <style>
    ul li { margin-bottom: 9px; }
    ol li { margin-bottom: 9px; }
   </style>
   
   <link rel="alternate" type="application/rss+xml" title="free range statistics by Peter Ellis"
      href="/feed.xml">

	  

      
		</head>
      
  <body role = "document">
  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
        <script src="/js/bootstrap.min.js"></script>
        
		<div id="fb-root"></div>
		<script>(function(d, s, id) {
		  var js, fjs = d.getElementsByTagName(s)[0];
		  if (d.getElementById(id)) return;
		  js = d.createElement(s); js.id = id;
		  js.src = "//connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.6";
		  fjs.parentNode.insertBefore(js, fjs);
		}(document, 'script', 'facebook-jssdk'));</script>
  
  <script>
  (function() {
    var cx = '015640467633673901770:pk3v2c95baw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>

  
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">free range statistics</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="/about">about</a></li>
            <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">all posts <span class="caret"></span></a>
                <ul class="dropdown-menu">
                  <li><a href="/blog">ordered by date</a></li>
	        <!--	  <li><a href="/blog/most-popular.html">ordered by popularity</a></li> -->
                  <li><a href="/blog/index_by_tag.html">grouped by subject matter</a></li>
                  <li><a href="/blog/pacific.html">all posts with data about Pacific island countries and territories</a></li>
                  <li><a href="/blog/nz.html">all posts with data about New Zealand</a></li>
				  <li><a href="/blog/voting.html">all posts on voting behaviour</a></li>
                  <li><a href="/blog/surveys.html">all posts on surveys</a></li> 
				  <li><a href = /blog/2026/02/08/social-table-visualisations>most recent post</a></li>
				</ul>
            </li>
              <li><a href="/blog/showcase.html">showcase</a></li>
              <li><a href="/presentations/index.html">presentations</a></li>
			  <li class="dropdown">
				<a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">forecasts<span class="caret"></span></a>
                <ul class="dropdown-menu">
				  <li><a href = "/covid-tracking/index.html">Covid-19 in Australia</a></li>
                  <li><a href = "/elections/nz-2020/index.html">NZ election 2020</a></li>
                  <li><a href = "/elections/oz-2019/index.html">Australia federal election 2019</a></li>
				  <li><a href = "/elections/nz-2017/combined.html">NZ election 2017</a></li>
                  <li><a href="/blog/voting.html">all blog posts on voting behaviour</a></li>
                </ul>				
			  </li>
			  
			  
			  
		    </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
  
  
      
			<div class="container">
			
			<div class="jumbotron">
  <div class="container">
	<center><h1>Power and 'fragile' p-values</h1></center>
  </div>
</div>



	<div class = "post-summary">
	<h2>At a glance:</h2>
	   <p>What proportion of significant <i>p</i> values should be between 0.01 and 0.05? Turns out the answer is 'it depends'.</p>
	   <p class="meta">08 Jun 2025</p>
	   <hr></hr>
	</div>


<div class="col-md-7">

	<div class="post">
		
	  <h3 id="do-fragile-p-values-tell-us-anything">Do ‘fragile’ <i>p</i> values tell us anything?</h3>
<p>I was interested recently to see <a href="https://journals.sagepub.com/doi/10.1177/25152459251323480">this article on <i>p</i> values in the psychology literature</a> float across my social media feed. Paul C Bogdan makes the case that the severity of the <a href="https://en.wikipedia.org/wiki/Replication_crisis">replication crisis</a> in science can be judged in part by the proportion of <i>p</i> values that are ‘fragile’,which he defines as between 0.01 and 0.05.</p>

<p>Of course, concern at the proportion of <i>p</i> values that are ‘significant but only just’ is a stable feature of the replication crisis. One of the standing concerns with science is that researchers use questionable research practices to somehow nudge the <i>p</i> values down to just below the threshold deemed to be “signficant” evidence. Another standing concern is that researchers who might not use those practices in the analysis themselves will not publish or not be able to publish their null results, leaving a bias towards positive results in the published literature (the <a href="https://en.wikipedia.org/wiki/Publication_bias#:~:text=This%20term%20suggests%20that%20negative,a%20bias%20in%20published%20research.">“file-drawer” problem</a>).</p>

<p>Bogdan argues that for studies with 80% power (defined as 1 minus the probability of accepting the null hypothesis when there is in fact a real effect in the data), 26% of <i>p</i> values that are significant should be in this “fragile” range, based on simulations.</p>

<p>The research Bogdan describes in the article linked above is a clever data processing exercise of published psychology literature to see what proportion of <i>p</i> values are in fact, “fragile” and how this changes over time. He finds that “From before the replication crisis (2004–2011) to today (2024), the overall percentage of significant <i>p</i> values in the fragile range has dropped from 32% to nearly 26%”. As 26% is about what we’d expect, if all the studies had power of 80%, then this is seen as good news.</p>

<p>Is the replication crisis over? (to be fair, I don’t think Bogdan claims this last point).</p>

<p>One of Bogdan’s own citations is <a href="https://peerj.com/articles/1142/">this piece by Daniel Lakens</a>, which itself is a critique of a similar attempt at this earlier. Lakens argues “the changes in the ratio of fractions of p-values between 0.041–0.049 over the years are better explained by assuming the average power has decreased over time” rather than by changes in questionable research practices. I think I agree with Lakens on this.</p>

<p>I just don’t think the 26% of significant <i>p</i> values to be ‘fragile’ is a solid enough benchmark to judge research pracices on.</p>

<p>Anyway, all this intrigued me enough when it was discussed first in <a href="https://www.science.org/content/article/big-win-dubious-statistical-results-are-becoming-less-common-psychology">Science</a> (as “a big win”) and then on <a href="https://bsky.app/profile/jbakcoleman.bsky.social/post/3lqyuqimtq22a">Bluesky</a> for me to want to do my own simulations to see how changes in effect sizes and sample sizes would change that 26%. My hunch was 26% was based on assumptions that all studies have 80% power and (given power has to be calculated for some assumed but unobserved true effect size) that the actual difference in the real world is close to the difference assumed in making that power calculation. Both these assumptions are obviously extremely brittle, but what is the impact if they are wrong?</p>

<p>From my rough playing out below, the impact is pretty material. We shouldn’t think that changes in the proportion of signficant <i>p</i> values that are between 0.01 and 0.05 tells us much about questionable research practices, because there is just too much else going on — pre-calculated power, how much power calculations and indeed the research that is chosen are based on a good reflection of reality, the size of differences we’re looking for, and sample sizes — confounding the whole thing.</p>

<h3 id="do-your-own-research-simulations">Do your own <s>research</s> simulations</h3>
<p>To do this, I wrote a simple function <code class="language-plaintext highlighter-rouge">experiment</code> which draws two independent samples from two populations, all observations normally distributed. For my purposes the two sample sizes are going to be the same and the standard deviations the same in both populations; only the means differ by population. But this function is set up for a more general exploration if I’m ever motivated.</p>

<h4 id="the-ideal-situation---researchers-power-calculation-matches-the-real-world">The ideal situation - researcher’s power calculation matches the real world</h4>
<p>With this function I first played around a bit to get a situation where the power is very close to 80%. I got this with sample sizes of 53 each and a difference in the means of the two populations of 0.55 (remembering each population has a standard distribtuion of N(0, 1)).</p>

<p>I then checked this with a published power package, <i>Bulus, M. (2023). <code class="language-plaintext highlighter-rouge">pwrss</code>: Statistical Power and Sample Size Calculation Tools. R package version 0.3.1. https://CRAN.R-project.org/package=pwrss</i>. I’ve never used this before and just downloaded it to check I hadn’t made mistakes in my own calculations, and later I will use it to speed up some stuff.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">pwrss</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">

</span><span class="n">experiment</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">m1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">sd2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">n2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">seed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NULL</span><span class="p">){</span><span class="w">
  </span><span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="nf">is.null</span><span class="p">(</span><span class="n">seed</span><span class="p">)){</span><span class="w">
    </span><span class="n">set.seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span><span class="w">
  </span><span class="p">}</span><span class="w">
  </span><span class="n">x1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">m1</span><span class="p">,</span><span class="w"> </span><span class="n">sd1</span><span class="p">)</span><span class="w">
  </span><span class="n">x2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n2</span><span class="w"> </span><span class="p">,</span><span class="n">m1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">sd2</span><span class="p">)</span><span class="w">
  </span><span class="n">t.test</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">)</span><span class="o">$</span><span class="n">p.value</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">reps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10000</span><span class="w">
</span><span class="n">res</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">numeric</span><span class="p">(</span><span class="n">reps</span><span class="p">)</span><span class="w">

</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">reps</span><span class="p">){</span><span class="w">
  </span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">experiment</span><span class="p">(</span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.55</span><span class="p">,</span><span class="w"> </span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">53</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>Yes, that’s right, I’m using a <code class="language-plaintext highlighter-rouge">for</code> loop here. Why? Because it’s very readable, and very easy to write.</p>

<p>Here’s what that gives us. My simulated power is 80%, Bulus’ package agrees with 80%, and 27% of the ‘signficant’ (at alpha = 0.05) <i>p</i> values are in the fragile range. This isn’t the same as 26% but it’s not a million miles away; it’s easy to imagine a few changes in the experiment that would lead to his 26% figure.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; # power from simulation
&gt; 1 - mean(res &gt; 0.05)
[1] 0.7964
&gt; 
&gt; # power from Bulus' package
&gt; pwrss.t.2means(mu1 = 0.55, sd1 = 1, sd2 = 1, n2 = 53)
 Difference between Two means 
 (Independent Samples t Test) 
 H0: mu1 = mu2 
 HA: mu1 != mu2 
 ------------------------------ 
  Statistical power = 0.801 
  n1 = 53 
  n2 = 53 
 ------------------------------ 
 Alternative = “not equal” 
 Degrees of freedom = 104 
 Non-centrality parameter = 2.831 
 Type I error rate = 0.05 
 Type II error rate = 0.199 
&gt; 
&gt; # Of those experiments that have 'significant' results, what proportion are in 
&gt; # the so-called fragile range (i.e. betwen 0.01 and 0.05)
&gt; summ1 &lt;- mean(res &gt; 0.01 &amp; res &lt; 0.05) / mean(res &lt; 0.05)
&gt; print(summ1)
[1] 0.2746107
</code></pre></div></div>

<h4 id="changes-in-difference-and-in-sample-size">Changes in difference and in sample size</h4>

<p>I made some arbitrary calls in that first run — sample size about 50 observations in each group, and the difference about 0.5 standard deviations. What if I let the difference between the two populations be smaller or larger than this, and just set the number of observations to whatever is necessary to get 80% power? What change does this make to the proportion of <i>p</i> values that are ‘fragile’?</p>

<p>It turns out it makes a <em>big</em> difference, as we see in these two charts:</p>

<object type="image/svg+xml" data="/img/0295-fragile-diff.svg" width="100%"><img src="/img/0295-fragile-diff.png" width="100%" /></object>
<object type="image/svg+xml" data="/img/0295-fragile-n.svg" width="100%"><img src="/img/0295-fragile-n.png" width="100%" /></object>

<p>These are simulations, still in the world where the researcher happens to guess the real world exactly right when they do their power calculation and determine a sample size to get 80% power. We see in the top chart that as the real world difference gets bigger, with constant power, the proportion of significant but ‘fragile’ <i>p</i> values goes up markedly. And the second chart shows the same simulations, but focusing on the variation in sample size which changes in compensation for the real world difference in populations, to maintain the same power. Bigger samples with the same power mean that you are looking for relatively smaller real world differences, and the proportion of significant <i>p</i> values that are ‘fragile’ gets smaller.</p>

<p>Here’s the code that did these simulations:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1">#--------------varying difference and sample sizes---------------</span><span class="w">
</span><span class="n">possible_diffs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10</span><span class="o">:</span><span class="m">200</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="c1"># measured in standard deviations</span><span class="w">

</span><span class="c1"># what sample size do we need to have 80% power</span><span class="w">
</span><span class="n">n_for_power</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sapply</span><span class="p">(</span><span class="n">possible_diffs</span><span class="p">,</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">d</span><span class="p">){</span><span class="w">
  </span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">pwrss.t.2means</span><span class="p">(</span><span class="n">mu1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">power</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.8</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="o">$</span><span class="n">n</span><span class="p">[</span><span class="m">1</span><span class="p">])</span><span class="w">
</span><span class="p">})</span><span class="w">

</span><span class="n">prop_fragile</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">numeric</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">possible_diffs</span><span class="p">))</span><span class="w">

</span><span class="c1"># This takes some minutes to run, could be better if parallelized or done in</span><span class="w">
</span><span class="c1"># Julia if we thought saving those minutes was important:</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="nf">length</span><span class="p">(</span><span class="n">possible_diffs</span><span class="p">)){</span><span class="w">
  </span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">reps</span><span class="p">){</span><span class="w">
    </span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">experiment</span><span class="p">(</span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">possible_diffs</span><span class="p">[</span><span class="n">j</span><span class="p">],</span><span class="w"> </span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_for_power</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="w">
  </span><span class="p">}</span><span class="w">
  </span><span class="n">prop_fragile</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">0.01</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">res</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># Plot 1</span><span class="w">
</span><span class="n">tibble</span><span class="p">(</span><span class="n">prop_fragile</span><span class="p">,</span><span class="w"> </span><span class="n">possible_diffs</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> 
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">possible_diffs</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="w"> </span><span class="n">prop_fragile</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_continuous</span><span class="p">(</span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">percent</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Difference (in standard deviations) between two means"</span><span class="p">,</span><span class="w">
       </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Proportion of significant p values \nthat are between 0.01 and 0.05"</span><span class="p">,</span><span class="w">
       </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Two sample tests for difference between two means with power = 80%"</span><span class="p">,</span><span class="w">
       </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"t test for independent samples at a combination of sample size and population difference\nneeded to give the desired power. Both populations are standard normal distributions."</span><span class="p">)</span><span class="w">

</span><span class="c1"># Plot 2</span><span class="w">
</span><span class="n">tibble</span><span class="p">(</span><span class="n">prop_fragile</span><span class="p">,</span><span class="w"> </span><span class="n">n_for_power</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> 
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_for_power</span><span class="p">,</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prop_fragile</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_sqrt</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_continuous</span><span class="p">(</span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">percent</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Sample size needed to get 80% power for given difference of means"</span><span class="p">,</span><span class="w">
       </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Proportion of significant p values \nthat are between 0.01 and 0.05"</span><span class="p">,</span><span class="w">
       </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Two sample tests for difference between two means with power = 80%"</span><span class="p">,</span><span class="w">
       </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"t test for independent samples at a combination of sample size and population difference\nneeded to give the desired power. Both populations are standard normal distributions."</span><span class="p">)</span></code></pre></figure>

<h4 id="relaxing-assumptions">Relaxing assumptions</h4>
<p>OK, so that was what we get when the power calculation was based on a true representation of the world, known before we did the experiment. Obviously this is never the case (or we’d not need to do experiments) — the actual difference between two populations might be bigger or smaller than we expected, it might actually be exactly zero, the shape and spread of the populations will differ from what we thought when we calculated the power, etc.</p>

<p>I decided to try three simple breaks of the assumptions to see what impact they have on the 27% of <i>p</i> values that were fragile:</p>
<ul>
  <li>The actual difference between populations is a random number, albeit on average is what is expected during the power calculation</li>
  <li>the actual difference between populations is a coin flip between exactly what was expected (when the power calculation was made) and zero (ie null hypothesis turns out to be true)</li>
  <li>the actual difference between population is a coin flip between a random number with average the same as expected and zero (ie a combination of the first two scenarios)</li>
</ul>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1">#------------------when true d isn't what was expected---------------</span><span class="w">

</span><span class="n">reps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10000</span><span class="w">
</span><span class="n">res</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">numeric</span><span class="p">(</span><span class="n">reps</span><span class="p">)</span><span class="w">

</span><span class="c1"># we are going to let the actual difference deviate from that which was used</span><span class="w">
</span><span class="c1"># in the power calculation, but say that on average the planned-for difference</span><span class="w">
</span><span class="c1"># was correct</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">reps</span><span class="p">){</span><span class="w">
  </span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">experiment</span><span class="p">(</span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0.55</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">),</span><span class="w"> </span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">53</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># "actual" power:</span><span class="w">
</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w">

</span><span class="c1"># proportion of so-called fragile p values is much less</span><span class="w">
</span><span class="n">summ2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">0.01</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">res</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w">

</span><span class="c1">#---------when true d is same as expected except half the time H0 is true---------</span><span class="w">

</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">reps</span><span class="p">){</span><span class="w">
  </span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">experiment</span><span class="p">(</span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0.55</span><span class="p">),</span><span class="w"> </span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">53</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">


</span><span class="c1"># proportion of so-called fragile p values is now *more*</span><span class="w">
</span><span class="n">summ3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">0.01</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">res</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w">

</span><span class="c1">#---------when true d is random, AND half the time H0 is true---------</span><span class="w">

</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">reps</span><span class="p">){</span><span class="w">
  </span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">experiment</span><span class="p">(</span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0.55</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">)),</span><span class="w"> </span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">53</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">


</span><span class="c1"># proportion of so-called fragile p values is now less</span><span class="w">
</span><span class="n">summ4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">0.01</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">res</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w">

</span><span class="n">tibble</span><span class="p">(</span><span class="n">`Context`</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="w">
  </span><span class="s2">"Difference is as expected during power calculation"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Difference is random, but on average is as expected"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Difference is as expected, except half the time null hypothesis is true"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Difference is random, AND null hypothesis true half the time"</span><span class="w">
</span><span class="p">),</span><span class="w"> </span><span class="n">`Proportion of p-values that are fragile`</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">summ1</span><span class="p">,</span><span class="w"> </span><span class="n">summ2</span><span class="p">,</span><span class="w"> </span><span class="n">summ3</span><span class="p">,</span><span class="w"> </span><span class="n">summ4</span><span class="p">))</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> 
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">across</span><span class="p">(</span><span class="n">where</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">),</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="n">percent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">accuracy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)))</span><span class="w"> </span></code></pre></figure>

<p>That gets us these interesting results:</p>

<table class=" lightable-material" style="font-family: &quot;Source Sans Pro&quot;, helvetica, sans-serif; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Context </th>
   <th style="text-align:left;"> Proportion of p-values that are fragile </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> Difference is as expected during power calculation </td>
   <td style="text-align:left;"> 27% </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Difference is random, but on average is as expected </td>
   <td style="text-align:left;"> 16% </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Difference is as expected, except half the time null hypothesis is true </td>
   <td style="text-align:left;"> 29% </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Difference is random, AND null hypothesis true half the time </td>
   <td style="text-align:left;"> 20% </td>
  </tr>
</tbody>
</table>

<hr />

<p>There’s a marked variation here in what proportion of <i>p</i> values is fragile. Arguably, the fourth of these scenarios is the closest approximation to the real world (although there is a lot of debate about this, how much are exactly-zero differences really plausible?) Either this, or the other realistic scenario (‘difference is random but on average is as expected’) gives a proportion of fragile <i>p</i> values well below the 27% we saw in our base scenario.</p>

<h3 id="conclusion">Conclusion</h3>

<p>There’s just too many factors impacting on the proportion of <i>p</i> values that will be between 0.01 and 0.05 to assume that variations in it are either an improvement or a worsening in research practices. These things include:</p>

<ul>
  <li>When expected differences change and sample sizes change to go with them for a given level of power, it impacts materially on the proportion of fragile <i>p</i> values we’d expect to see</li>
  <li>When the real world differs from that expected by the researcher when they did their power calculation, it impacts materially on the proportion of fragile <i>p</i> values we’d expect to see</li>
  <li>Anyway, researchers don’t all set their sample sizes to give 80% power, for various reasons, some of them good and some not so good</li>
</ul>

<p>Final thought — none of the above tells us whether we have a replication crisis or not, and if so if it’s getting better or getting worse. As it happens, I tend to think we do have one and that it’s very serious. I think the peer review process works very poorly and <a href="/blog/2020/06/13/publication-reform">could be improved</a>, and academic publishing in general sets up terrible — and perhaps worsening — incentives. However, I think criticism in the past decade or so has led to improvements (such as more access to reproducible code and data, more pre-registration, general raised awareness), which is consistent really with Bogdan’s substantive argument here. I just don’t think the ‘fragile’ <i>p</i> values are much evidence either way, and if we monitor them at all we should do so with great caution.</p>


		
	</div>
</div>

<div class="col-md-1"></div>
<div class="col-md-4">
	<div class="side-banner">
	


	<div>
	   
	    
			
			<p>&larr; Previous post</p>
			<p><a rel="prev" href="/blog/2025/05/17/animated-population-pyramids">Animated population pyramids for the Pacific</a></p>
		
		
		
		
		 
			
			<p>Next post &rarr;</p>
			<p><a rel="next" href="/blog/2025/06/14/more-on-fragile-p-values">More on power and 'fragile' p-values</a></p>
			
			
		
		
	</div>
	
	 

   <div class = "side-footer">
			
			<hr></hr>
			<p><gcse:search></gcse:search></p>
			<hr></hr>

			<p>My day job is Director of the <a href='https://sdd.spc.int/'>Statistics for Development Division</a> at the Pacific Community, the principal scientific and technical organisation in the Pacific region, proudly supporting development since 1947. We are an international development organisation owned and governed by our 27 country and territory members. This blog is not part of my role there and contains my personal views only.</p>
		
		    <hr></hr>
			
        	<p>Follow <a href = "/feed.xml">this blog with RSS</a>.</p>
			<p>Find me on <a rel="me" href="https://bsky.app/profile/freerangestats.info">Bluesky</a> or <a rel="me" href="https://mastodon.social/@peter_ellis">Mastodon</a>.</p>
			<hr></hr>
			


       <div class="fb-like" data-href="https://www.facebook.com/peterstats/" data-layout="standard" data-action="like" data-show-faces="false" data-share="false"></div>
			
			<hr></hr>
			<p>I'm pleased to be aggregated at <a href="https://www.r-bloggers.com/">R-bloggers</a>, the one-stop shop for blog posts featuring R.</p>
			
			<p>I've never been an academic but have written a few small things and hence have a <a href='https://scholar.google.com/citations?view_op=list_works&hl=en&user=MEtLNDMAAAAJ'>Google Scholar profile</a></p>
			
			<p>I read a lot of books. In the unlikely event you want to see what I think about them or what I'm reading at the moment, <a href='https://www.goodreads.com/user/show/55517482-peter-ellis'>follow me on Goodreads</a>.</p>
			<hr></hr>

			
			<p>			
            <span xmlns:dct="https://purl.org/dc/terms/" property="dct:title"><i>free range statistics</i></span> by <a href = "/about/index.html">Peter Ellis</a> is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
			</p>

			<hr></hr>
			
			<h4>Bluesky feed:</h3>
         <script src="https://cdn.jsdelivr.net/npm/bsky-embed/dist/bsky-embed.es.js" async></script>
<bsky-embed  
  username="freerangestats.info"  
  limit="5"  
>  
</bsky-embed>

    </div>



  
   




		  
		  



	   
	<div id="disqus_thread"></div>

		<script type="text/javascript">
			/* * * CONFIGURATION VARIABLES * * */
			var disqus_shortname = 'statsinthewild';
			
			/* * * DON'T EDIT BELOW THIS LINE * * */
			(function() {
				var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
				dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
				(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
			})();
		</script>

		<script type="text/javascript">
			/* * * CONFIGURATION VARIABLES * * */
			var disqus_shortname = 'statsinthewild';
			
			/* * * DON'T EDIT BELOW THIS LINE * * */
			(function () {
				var s = document.createElement('script'); s.async = true;
				s.type = 'text/javascript';
				s.src = '//' + disqus_shortname + '.disqus.com/count.js';
				(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
			}());
		</script>

	<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
	</div>	
</div>    
   
   

			
			</div><!-- /.container -->
         
   <!-- Default Statcounter code for Free Range Statistics https://freerangestats.info -->
<script type="text/javascript">
var sc_project=11673245; 
var sc_invisible=1; 
var sc_security="5b7111a4"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img class="statcounter"
src="//c.statcounter.com/11673245/0/5b7111a4/1/" alt="Web
Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->

</body>   
</html>