      <!DOCTYPE html>
	<html lang="en">
		<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
			<title>Poisson point processes, mass shootings and clumping</title>
      	
         
         
            <meta name ="description" content ="I annotate and explain an example use of Poisson process modelling to test an important hypothesis about the frequency of mass shootings in Australia over time.">
            <meta property="og:description" content ="I annotate and explain an example use of Poisson process modelling to test an important hypothesis about the frequency of mass shootings in Australia over time.">
         
         <meta property="og:site_name" content="free range statistics" />
         <meta property="og:title" content="Poisson point processes, mass shootings and clumping" />
         
            <meta property="og:image" content="http://freerangestats.info/img/0158-events.png" />
         
		 
			<meta property="og:url" content="http://freerangestats.info/blog/2019/09/07/mass-shootings-oz.html" />
		 
         <meta property="og:author" content= "https://www.facebook.com/peterstats" />
         <meta property="og:type" content="article" />
      

<link href='https://fonts.googleapis.com/css?family=Sarala' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Prosto+One' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet'>
	  
          <link href="/css/bootstrap.min.css" rel ="stylesheet" type="text/css">
          <link href="/css/bootstrap-theme.min.css" rel ="stylesheet" type="text/css">
            <link href="/css/custom.css" rel ="stylesheet" type="text/css">     
		<link href="/css/syntax.css" rel ="stylesheet" type="text/css">     			
                 
            
   <script>
     (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

     ga('create', 'UA-65886313-1', 'auto');
     ga('send', 'pageview');

   </script>
   
   <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

   <style>
    ul li { margin-bottom: 9px; }
    ol li { margin-bottom: 9px; }
   </style>
   
   <link rel="alternate" type="application/rss+xml" title="free range statistics by Peter Ellis"
      href="/feed.xml">

	  

      
		</head>
      
  <body role = "document">
  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
        <script src="/js/bootstrap.min.js"></script>
        
		<div id="fb-root"></div>
		<script>(function(d, s, id) {
		  var js, fjs = d.getElementsByTagName(s)[0];
		  if (d.getElementById(id)) return;
		  js = d.createElement(s); js.id = id;
		  js.src = "//connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.6";
		  fjs.parentNode.insertBefore(js, fjs);
		}(document, 'script', 'facebook-jssdk'));</script>
  
  <script>
  (function() {
    var cx = '015640467633673901770:pk3v2c95baw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>

  
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">free range statistics</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="/about">about</a></li>
            <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">all posts <span class="caret"></span></a>
                <ul class="dropdown-menu">
                  <li><a href="/blog">ordered by date</a></li>
				  <li><a href="/blog/most-popular.html">ordered by popularity</a></li>
                  <li><a href="/blog/index_by_tag.html">grouped by subject matter</a></li>
                  <li><a href="/blog/nz.html">all posts with data about new zealand</a></li>
				  <li><a href="/blog/voting.html">all posts on voting behaviour</a></li>
				  <li><a href = /blog/2020/01/26/tennis-seeding>most recent post</a></li>
				</ul>
            </li>
              <li><a href="/blog/showcase.html">showcase</a></li>
              <li><a href="/presentations/index.html">presentations</a></li>
			  <li class="dropdown">
				<a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">election forecasts<span class="caret"></span></a>
                <ul class="dropdown-menu">
                  <li><a href = "/elections/oz/index.html">Australia federal 2019</a></li>
				  <li><a href = "/elections/combined.html">NZ 2016</a></li>
                  <li><a href="/blog/voting.html">all posts on voting behaviour</a></li>
                </ul>				
			  </li>
			  
			  
			  
		    </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
  
  
      
			<div class="container">
			
			<div class="jumbotron">
  <div class="container">
	<center><h1>Poisson point processes, mass shootings and clumping</h1></center>
  </div>
</div>



	<div class = "post-summary">
	<h2>At a glance:</h2>
	   <p>I annotate and explain an example use of Poisson process modelling to test an important hypothesis about the frequency of mass shootings in Australia over time.</p>
	   <p class="meta">07 Sep 2019</p>
	   <hr></hr>
	</div>


<div class="col-md-7">

	<div class="post">
		
	  <h2 id="did-the-average-rate-of-australian-mass-shooting-decline-after-1996-or-was-the-drop-just-chance">Did the average rate of Australian mass-shooting decline after 1996, or was the drop just chance?</h2>

<p>I recently came across this letter to the Annals of Internal Medicine by Simon Chapman, Michael Stewart, Philip Alpers and Michael Jones: <a href="https://annals.org/aim/fullarticle/2675234/fatal-firearm-incidents-before-after-australia-s-1996-national-firearms">Fatal Firearm Incidents Before and After Australia’s 1996 National Firearms Agreement Banning Semiautomatic Rifles</a>, via <a href="https://www.guncontrol.nz/media/myths-propaganda-statistics-why-dr-samara-mcphedran-cant-be-belie">this piece</a> by Gun Control NZ.</p>

<p>The question under investigation is whether the drop in mass-shooting events in Australia since the change in the firearm regulatory environment in 1996 could be a result of chance or not. “Mass shootings” are defined as homicides in which at least five persons died, not including the perpetrator. There were 13 of these events in the 18 years from 1979 up to the time of the National Firearms Agreement, and none afterwards.</p>

<p>Chapman et al model the events with a <a href="https://en.wikipedia.org/wiki/Poisson_point_process">Poisson point process</a> and <a href="https://acp.silverchair-cdn.com/acp/content_public/journal/aim/937339/m18-0503_supplement.pdf?Expires=1567900673&amp;Signature=E6-Z~KyoSN8w5Q0vyXU1ypYoOOr4g05Vu5a3AHV~PbBj0ewSl7-cgJfvye7BV9DhonioJvK2SFb747-XVpGeuheaBHN0BRQLxPemmQIWyB7eXqyovfTmn6Kfa9Quh5FsLLgWPx-Syv7laz0RICZ9BVdb4bJzQkphRsrq1RMZm6bFWutH2Uoy-E772jI19KUJU1TGIW6AmvI5d1PU1TWHZF-wGwOYqSn-uBtaCVifpzL3MQ0EStdFlrJ55~We-K11wYPl~noH~lrFxDs0YuiM~MmuJzZQewEiAIpPNlfyCox4wrTdpSlmTMBEb1ArmED~JpgLxe7V29OKQV~MrVKIog__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">provide all of their R code</a> to replicate their findings. However, the code they provide is somewhat compact and tersely commented, and having familiarised myself with how it works I thought it worthwhile blogging about in a somewhat more verbose manner.</p>

<p>I am putting aside <a href="http://www.hoplofobia.info/wp-content/uploads/2015/08/2018-Kleck_Chapman_NFA_comments.pdf">controversies</a> about whether five persons is the correct threshold to consider, whether these events should be restricted only to deaths from rapid fire weapons, and analysis of general trends and possible confounding factors. For the purpose of this blog I am just approaching this as an edifying illustration of the modelling of Poisson point processes.</p>

<h2 id="data-familiarisation">Data familiarisation</h2>

<p>Let’s start with visualising the data. Here’s a chart showing each mass-shooting event as a vertical strip in comparison to the timing of the regulatory changes:</p>

<object type="image/svg+xml" data="/img/0158-events.svg" width="100%"><img src="/img/0158-events.png" /></object>

<p>That’s pretty dramatic and it passes Tukey’s intra-ocular impact significance test (ie hits you between the eyes)<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>. Here’s the code that sets up our data for that visulaisation and the more formal tests to come:</p>

<p><em>Post continues after R code</em></p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">NHPoisson</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">scales</span><span class="p">)</span><span class="w">

</span><span class="c1">#----------------Data prep and first visualisation----------------
</span><span class="w">
</span><span class="n">mass_shootings</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
  </span><span class="n">mon</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="m">8</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">12</span><span class="p">,</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="m">8</span><span class="p">,</span><span class="w"> </span><span class="m">8</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">),</span><span class="w">
  </span><span class="n">yr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1981</span><span class="p">,</span><span class="w"> </span><span class="m">1984</span><span class="p">,</span><span class="w"> </span><span class="m">1987</span><span class="p">,</span><span class="w"> </span><span class="m">1987</span><span class="p">,</span><span class="w"> </span><span class="m">1987</span><span class="p">,</span><span class="w"> </span><span class="m">1987</span><span class="p">,</span><span class="w"> </span><span class="m">1988</span><span class="p">,</span><span class="w"> </span><span class="m">1990</span><span class="p">,</span><span class="w"> </span><span class="m">1991</span><span class="p">,</span><span class="w"> </span><span class="m">1992</span><span class="p">,</span><span class="w"> </span><span class="m">1993</span><span class="p">,</span><span class="w"> </span><span class="m">1996</span><span class="p">,</span><span class="w"> </span><span class="m">1996</span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w"> 

</span><span class="n">mass_shootings</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mass_shootings</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">months</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">yr</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1979</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">mon</span><span class="p">,</span><span class="w">
         </span><span class="n">approx_date</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.Date</span><span class="p">(</span><span class="n">paste</span><span class="p">(</span><span class="n">yr</span><span class="p">,</span><span class="w"> </span><span class="n">mon</span><span class="p">,</span><span class="w"> </span><span class="m">15</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"-"</span><span class="p">)),</span><span class="w">
         </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">diff</span><span class="p">(</span><span class="n">approx_date</span><span class="p">)))</span><span class="w">

</span><span class="n">p</span><span class="m">1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">mass_shootings</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">xend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">approx_date</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">approx_date</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_rect</span><span class="p">(</span><span class="n">xmin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.Date</span><span class="p">(</span><span class="s2">"1996-07-15"</span><span class="p">),</span><span class="w"> </span><span class="n">xmax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">Inf</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="kc">Inf</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">Inf</span><span class="p">,</span><span class="w">
            </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"steelblue"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.01</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_rect</span><span class="p">(</span><span class="n">xmax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.Date</span><span class="p">(</span><span class="s2">"1996-07-15"</span><span class="p">),</span><span class="w"> </span><span class="n">xmin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="kc">Inf</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="kc">Inf</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">Inf</span><span class="p">,</span><span class="w">
            </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.01</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_segment</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="kc">Inf</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">Inf</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_date</span><span class="p">(</span><span class="n">limits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">mass_shootings</span><span class="o">$</span><span class="n">approx_date</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">50</span><span class="p">),</span><span class="w"> </span><span class="n">as.Date</span><span class="p">(</span><span class="s2">"2018-02-15"</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme</span><span class="p">(</span><span class="n">panel.grid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_blank</span><span class="p">(),</span><span class="w">
        </span><span class="n">panel.border</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_blank</span><span class="p">(),</span><span class="w">
        </span><span class="n">axis.text.y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_blank</span><span class="p">(),</span><span class="w">
        </span><span class="n">axis.ticks.y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_blank</span><span class="p">())</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Approximate date of mass shooting"</span><span class="p">,</span><span class="w">
       </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">""</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.Date</span><span class="p">(</span><span class="s2">"2008-01-01"</span><span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"After the gun buy-back"</span><span class="p">,</span><span class="w">
           </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"steelblue"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">ggtitle</span><span class="p">(</span><span class="s2">"Firearm-related homicides in Australia"</span><span class="p">,</span><span class="w"> 
          </span><span class="s2">"Events in which at least 5 persons other than perpetrator died"</span><span class="p">)</span><span class="w"> </span></code></pre></figure>

<h2 id="using-likelihood-ratio-to-compare-two-hypothesis">Using likelihood ratio to compare two hypothesis</h2>

<p>Chapman et al provide this table of results in their main article:</p>

<p><img src="/img/0158-chapman-results.jpeg" width="100%" /></p>

<p>The numbers above the line in that image are used to define:</p>

<ul>
  <li>their null hypothesis (that the underlying rate of mass shootings is the same over the whole period); and</li>
  <li>an alternative (that there are two different underlying rates, once in the first 210 months and once in the second:</li>
</ul>

<p>Under the null hypothesis we would expect to see 5.809 events in the first period of 210 months, then 7.191 in the second period of 260 months. Under the alternative hypothesis (which is purely driven by the data), we expect to see 13 in the first period and zero in the second.</p>

<h3 id="simple-calculation-of-the-likelihood-ratio-test">Simple calculation of the likelihood ratio test</h3>

<p>The likelihood ratio calculated under the heading of “Asymptotic (actual data)” comes directly from the known properties of a homogenous Poisson process. In such a process, events occur independently at intervals in time (and or space - these processes generalise to more than one dimension) which follow an exponential distribution. In any fixed amount of time, the count of events seen in such a process has a Poisson distribution; and the formula beginning “LR =” comes directly from calculating the likelihood of the observed data with such a distribution.</p>

<p>The ratio of 35,313.9 is how much more “likely” the data are to have been generated by the alternative hypothesis than the null. The calculation of the p value afterwards comes from conferting that ratio into a drop in “deviance” and comparing that to a Chi-squared distribution with one degree of freedom; the “alternative” hypothesis is one parameter more complex than the null (because there are two average rates of shootings over the full period, rather than one), so the drop in deviance we would expect to see from pure randomness if the null were true would follow that particular Chi-squared distribution.</p>

<p>It turns out that the actual drop in deviance (20.95) is far higher than can plausibly come from chance, with a p-value of 0.0000047.  All of this is textbook statistical inference and the calculations are produced with this code:</p>

<p><em>Post continues after R code</em></p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1">#-------------------------Modelling and likelihood ratio test-----------
# number of mass shootings in first period:
</span><span class="n">n_massacres</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">mass_shootings</span><span class="p">)</span><span class="w">

</span><span class="c1"># Expected mass shootings in each of the two periods, under constant rare events model:
</span><span class="n">lam0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="m">210</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">470</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n_massacres</span><span class="w">
</span><span class="n">lam1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="m">260</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">470</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n_massacres</span><span class="w">

</span><span class="c1"># Put those two expected values into a table:
</span><span class="n">cbind</span><span class="p">(</span><span class="n">lam0</span><span class="p">,</span><span class="w"> </span><span class="n">lam1</span><span class="p">)</span><span class="w"> 

</span><span class="c1"># Reduction in deviance comparing the two hypotheses
</span><span class="n">logLRobs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">dpois</span><span class="p">(</span><span class="n">n_massacres</span><span class="p">,</span><span class="w"> </span><span class="n">n_massacres</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w">
              </span><span class="p">(</span><span class="n">dpois</span><span class="p">(</span><span class="n">n_massacres</span><span class="p">,</span><span class="w"> </span><span class="n">lam0</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dpois</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">lam1</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)))</span><span class="w">

</span><span class="c1"># Print reduction in deviance to screen:			  
</span><span class="n">logLRobs</span><span class="w">

</span><span class="c1"># Calculate p-value if null hypothesis of a random drop in deviance:
</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pchisq</span><span class="p">(</span><span class="n">logLRobs</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span></code></pre></figure>

<p>That reproduces the results shown in the top half of the results</p>

<h3 id="robustness-check---one-more-event">Robustness check - “one more” event</h3>

<p>The results reported under “Asymptotic (perturbed data)” are the first robustness check conducted by Chapman et al. They considered “what if there had been one more massacre in the period after the regulatory changes - for example, as our article goes to print?”. This is a very sensible check.</p>

<p>The calculations are the same as in the original case, except that some zeroes become ones; the average rate under the null is now 14 / (210 + 260), and the expected number of events in the two periods goes to 6.255 and 7.745.  The reduction in deviance in this case is much less than previously, but the p value is still far below conventional threshold needed to dismiss the null hypothesis of a constant rate over the full period.</p>

<p><em>Post continues after R code</em></p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1">#--------------------------------Robustness - would an extra, late massacre matter?---------------
# Robustness check - what if there was an extra massacre happening in the post-buyback period
</span><span class="n">mu0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">((</span><span class="n">n_massacres</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="m">210</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">260</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">210</span><span class="w">
</span><span class="n">mu1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">((</span><span class="n">n_massacres</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="m">210</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">260</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">260</span><span class="w">
</span><span class="n">cbind</span><span class="p">(</span><span class="n">mu0</span><span class="p">,</span><span class="n">mu1</span><span class="p">)</span><span class="w">

</span><span class="n">logLRperturb</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">((</span><span class="n">dpois</span><span class="p">(</span><span class="n">n_massacres</span><span class="p">,</span><span class="w"> </span><span class="n">n_massacres</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dpois</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="o">-</span><span class="w">
                       </span><span class="p">(</span><span class="n">dpois</span><span class="p">(</span><span class="n">n_massacres</span><span class="p">,</span><span class="w"> </span><span class="n">mu0</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dpois</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">mu1</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)))</span><span class="w">
</span><span class="n">logLRperturb</span><span class="w">

</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pchisq</span><span class="p">(</span><span class="n">logLRperturb</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span></code></pre></figure>

<h3 id="robustness-check---resampling">Robustness check - resampling</h3>

<p>The above calculations depend upon the large sample properties of a homogenous Poisson point process. However, 13 events over 39 years is not a very large sample. So Chapman et al rightly did a further check of comparing the observed drop in deviance from null to alternative hypothesis, not with the theoretical Chi-square distribution but with the distribution of drops in deviance from a large set of data generated by computer under the null hypothesis. The result is the slightly higher but still vanishingly small p value of 0.0000069.</p>

<p>The original authors don’t report it, but the same comparison done to the drop in deviance under the “perturbed” set of data (with an extra mass shooting in the late period) gives a p value of 0.0002 - nearly twice the reported p value for the perturbed data from the asymptotic distribution, but still far too small to think that the reduction of mass shootings in the later period could plausibly be from chance with an average rate over the entire time period.</p>

<p><em>Post continues after R code</em></p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1">#------------Comparison with resampling----------------
# Force R to use non-uniform Rounding sampler, as per older versions of R, to get exact results
</span><span class="n">RNGkind</span><span class="p">(</span><span class="n">sample.kind</span><span class="o">=</span><span class="s2">"Rounding"</span><span class="p">)</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">20180226</span><span class="p">)</span><span class="w">

</span><span class="n">n_sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">20000000</span><span class="w">
</span><span class="n">logLRsim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n_sim</span><span class="p">){</span><span class="w">
  </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rpois</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">lam0</span><span class="p">)</span><span class="w">
  </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rpois</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">lam1</span><span class="p">)</span><span class="w">
  </span><span class="n">lam0sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="m">210</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">260</span><span class="p">)</span><span class="w">
  </span><span class="n">logL0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">dpois</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">lam0sim</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">210</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dpois</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">lam0sim</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">260</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
  </span><span class="n">logL1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">dpois</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dpois</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
  </span><span class="n">logLRsim</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">logL1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">logL0</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># Compare the drop of deviance actually observed with that simulated under the null hypothesis:
</span><span class="n">no_exceeding</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">logLRsim</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">logLRobs</span><span class="p">)</span><span class="w">
</span><span class="n">no_exceeding</span><span class="w">
</span><span class="n">no_exceeding</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_sim</span><span class="w">

</span><span class="c1"># same comparison, with the "one more recent massacre" perturbed data's drop in deviance:
</span><span class="n">no_exceeding_perturb</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">logLRsim</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">logLRperturb</span><span class="p">)</span><span class="w">
</span><span class="n">no_exceeding_perturb</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_sim</span></code></pre></figure>

<h2 id="investigating-clumping">Investigating clumping</h2>

<p>The final piece of analysis by the original authors was an investigation into whether “clumping” of events might invalidate their results. The above calculations, including those that compared the drop in deviance with simulated results that account for small sample, all rely on the model of the data as coming from a Poisson point process in the first place. A key part of that model is that events occur independently, in time intervals that follow an exponential distribution. If we look at the actual time intervals, we see that the exponential distribution is only an approximation, as of course is to be expected with real life data and a fairly small sample:</p>

<object type="image/svg+xml" data="/img/0158-exp-distribution.svg" width="100%"><img src="/img/0158-exp-distribution.png" /></object>

<p>The grey shaded area is the empirical distribution of the intervals between events and the blue line is the theoretical exponential distribution under the “two different underlying rate” alternative hypothesis. That graphic was made with this code:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ggplot</span><span class="p">(</span><span class="n">mass_shootings</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jitter</span><span class="p">(</span><span class="n">interval</span><span class="p">,</span><span class="w"> </span><span class="m">2.5</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_density</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"grey"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NA</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_rug</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dexp</span><span class="p">,</span><span class="w"> 
                </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">rate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">mass_shootings</span><span class="o">$</span><span class="n">interval</span><span class="p">,</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)),</span><span class="w"> 
                </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"blue"</span><span class="p">,</span><span class="w">
                </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Interval between mass shootings in Australia 1981 to 1996"</span><span class="p">,</span><span class="w">
       </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Comparison of intervals between mass shooting with theoretical independence"</span><span class="p">,</span><span class="w">
       </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"There are fewer close-together shootings, and more far-apart, than expected from exponential distribution"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_continuous</span><span class="p">(</span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">comma</span><span class="p">)</span></code></pre></figure>

<p>Interestingly, four very evenly spaced mass shooting events in 1987 were each 61 days apart (after my approximation of saying all events are on the 15th of the month - I don’t have the exact dates, only the month of occurrence) so I had to jitter the data a bit for it all to show up in the “rug marks” along the bottom of that plot.</p>

<p>A critique of some of Chapman’s earlier work in this space had suggested that the pre-1996 shootings were a cluster of non-independent events. In analysis of stochastic processes this is called “clumping”, a term that is more intuitive when considering a two dimensional Poisson point process for the positioning of (for example) trees than events in time, but the principle is the same. If, for example, mass shootings led to copycat events at relatively short intervals, followed by long periods when no-one breaks the ice with a shooting, then the statistical tests in the analysis so far would be over-stating the evidence against a constant underlying rate of mass shootings.</p>

<p>To check against this, Chapman et al used some elegant techniques to compare the clumping in the observed data to the amount of clumping seen in genuine Poisson processes. For this step, the null hypothesis is that the data are from a genuine Poisson process, and we are looking for evidence against that null hypothesis in the form of a p value suggesting that the observed data are unlikely (too clumpy) to have come from such a process. This is all done with simulation methods.</p>

<p>They start this check by observing the highest number of events per window in simulated data (up to a window of 18 months), and storing this in an object called <code class="highlighter-rouge">max_stat_mat</code> in the code below (differently named in their original code). Then, with the actual data, they calculate for each possible window the highest number of events taking place within that window - and compare this to its place in the distribution of the simulated data.  This gives us a set of raw p values for how unlikely the clumping is for each window:</p>

<table class="table" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:right;"> window </th>
   <th style="text-align:right;"> stat_obs </th>
   <th style="text-align:right;"> p_vals </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 1.0000 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 2 </td>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 1.0000 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 2 </td>
   <td style="text-align:right;"> 0.7522 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 2 </td>
   <td style="text-align:right;"> 0.8542 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 0.2143 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 6 </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 0.3067 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 7 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.0488 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 8 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.0734 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 9 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.1058 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 10 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.1434 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 11 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.1842 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 12 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.2258 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 13 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.2693 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 14 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.3074 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 0.3531 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 16 </td>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 0.0990 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 17 </td>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 0.1226 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 18 </td>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 0.1482 </td>
  </tr>
</tbody>
</table>

<p>The most suspect window length is 7 months. For this window, the observed clumping was more than 95.1% of the simulations. However, we can’t use this p value of 0.049 to reject the null hypothesis of no clumping yet, because we have chosen that null hypothesis only after observing the data (that is, we picked 7 months as the window most likely to show clumping from the data). To get a “proper” p value we need to adjust this again by comparing to what we would have seen by chance. That is, some window is always going to generate the lowest p value by this method; how often will it be as low as 0.049? Adjusting it this way gets us an actual p value of 0.095 - not low enough to dismiss the null hypothesis of the data coming from a genuine Poisson process.</p>

<p>An interesting point about reproducibility here. When I first ran the code directly from the supplement to the original article, I got different results at this point to those reported, although still in line with the substantive conclusions. One of the original authors, Michael Stewart, was able to put me on to the reason why. From version 3.6.0, <a href="https://blog.revolutionanalytics.com/2019/05/whats-new-in-r-360.html">R changed its method of random number generation</a>, which can lead to small (but sometimes material) differences when running simulations from older versions of R even if the random seed is set. In the code for this blog, I used <code class="highlighter-rouge">RNGkind(sample.kind="Rounding")</code> early in the script to revert to the old behaviour. This is certainly something worth knowing about when trying to reproduce pre-2019 simulation results.</p>

<p>I think I further complicate reproducibility through my code additions - and in particular the use of randomness in <code class="highlighter-rouge">jitter</code> to help show up the rugs in one of my plots. My eventual results are close enough to the published not to worry about this, but it’s something worth remembering when going for strict reproducibility, that randomness comes in a lot of ways. For robust reproducibility, it would be sensible to set the random seed with <code class="highlighter-rouge">set.seed()</code> before each key piece of simulation analysis, to control for dangers coming from restructuring code.</p>

<p><em>Post continues after R code</em></p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="cd">#' Calculate the highest number of events in a given window
#' 
#' @param months a vector of times at which events took place
#' @param window length of window
#' @return The highest number of events occuring in the given window of time, in the given list of intervals of events
</span><span class="n">scan_stat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">months</span><span class="p">,</span><span class="w"> </span><span class="n">window</span><span class="p">){</span><span class="w">
  </span><span class="n">sum_window</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="m">210</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">window</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">)){</span><span class="w">
    </span><span class="n">sum_window</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">((</span><span class="n">j</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">months</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">months</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">window</span><span class="p">))</span><span class="w">
  </span><span class="p">}</span><span class="w">
  </span><span class="nf">max</span><span class="p">(</span><span class="n">sum_window</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">


</span><span class="c1">#### Simulated data from a theoretical poisson process
</span><span class="n">n_sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10000</span><span class="w">
</span><span class="n">max_window</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">18</span><span class="w">

</span><span class="c1"># matrix to hold results for simulated data
</span><span class="n">max_stat_mat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">n_sim</span><span class="p">,</span><span class="w"> </span><span class="n">max_window</span><span class="p">)</span><span class="w">

</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n_sim</span><span class="p">){</span><span class="w">
  </span><span class="n">N</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rpois</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_massacres</span><span class="p">)</span><span class="w">
  </span><span class="n">months_sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sort</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">210</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">repl</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">))</span><span class="w">
  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">max_window</span><span class="p">){</span><span class="w">
    </span><span class="n">max_stat_mat</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">scan_stat</span><span class="p">(</span><span class="n">months_sim</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">


</span><span class="c1">#### Compare what actually happened to the simulated data
</span><span class="n">p_vals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">stat_obs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">window</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">max_window</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">k</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">window</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">stat_obs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">scan_stat</span><span class="p">(</span><span class="n">mass_shootings</span><span class="o">$</span><span class="n">months</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="p">)</span><span class="w">
  </span><span class="n">p_vals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">max_stat_mat</span><span class="p">[,</span><span class="w"> </span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">stat_obs</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># all unadjusted p values:
</span><span class="n">cbind</span><span class="p">(</span><span class="n">window</span><span class="p">,</span><span class="w"> </span><span class="n">stat_obs</span><span class="p">,</span><span class="w"> </span><span class="n">p_vals</span><span class="p">)</span><span class="w"> 

</span><span class="c1"># the lowest unadjusted p value:
</span><span class="n">unadj_pval</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">min</span><span class="p">(</span><span class="n">p_vals</span><span class="p">)</span><span class="w">

</span><span class="c1"># adjust that p value for all the data dredging we've done so far by comparing our result (lowest p value)
# to what we get by simulating everything from an actual Poisson process
</span><span class="n">M_sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10000</span><span class="w">
</span><span class="n">pvals_sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">min_pval_sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">M_sim</span><span class="p">){</span><span class="w">
  </span><span class="n">N</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rpois</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_massacres</span><span class="p">)</span><span class="w">
  </span><span class="n">months_sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sort</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">210</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="n">repl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">))</span><span class="w">
  </span><span class="n">stat_obs_sim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">window</span><span class="p">){</span><span class="w">
    </span><span class="n">stat_obs_sim</span><span class="p">[</span><span class="n">b</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">scan_stat</span><span class="p">(</span><span class="n">months_sim</span><span class="p">,</span><span class="n">b</span><span class="p">)</span><span class="w">
    </span><span class="n">pvals_sim</span><span class="p">[</span><span class="n">b</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">max_stat_mat</span><span class="p">[,</span><span class="n">b</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">stat_obs_sim</span><span class="p">[</span><span class="n">b</span><span class="p">])</span><span class="w">
  </span><span class="p">}</span><span class="w">
  </span><span class="n">min_pval_sim</span><span class="p">[</span><span class="n">a</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">min</span><span class="p">(</span><span class="n">pvals_sim</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># On average, how often is the minimum p value we just simulated less than the unadjusted p value
# we got from the comparison of data to simulations?
</span><span class="n">adj_pval</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">min_pval_sim</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">unadj_pval</span><span class="p">)</span><span class="w">
</span><span class="n">adj_pval</span></code></pre></figure>

<h2 id="conclusion">Conclusion</h2>

<p>This analysis is pretty robust. As the original authors state:</p>

<blockquote>
  <p>a standard rare events model provides strong evidence against the hypothesis that this prolonged absence simply reflects a continuation of a preexisting pattern of rare events.</p>
</blockquote>

<p>So taken as a given issues such as whether the 13 events are the right ones to count and what to do about other confounding trends, we can be pretty confident in that conclusion.</p>

<h2 id="changes-i-made-in-the-original-code">Changes I made in the original code</h2>

<p>If you compare my <a href="https://github.com/ellisp/blog-source/blob/master/_working/0158-rare-events-massacres.R">eventual R script</a> I used for this blog with <a href="https://acp.silverchair-cdn.com/acp/content_public/journal/aim/937339/m18-0503_supplement.pdf?Expires=1567900673&amp;Signature=E6-Z~KyoSN8w5Q0vyXU1ypYoOOr4g05Vu5a3AHV~PbBj0ewSl7-cgJfvye7BV9DhonioJvK2SFb747-XVpGeuheaBHN0BRQLxPemmQIWyB7eXqyovfTmn6Kfa9Quh5FsLLgWPx-Syv7laz0RICZ9BVdb4bJzQkphRsrq1RMZm6bFWutH2Uoy-E772jI19KUJU1TGIW6AmvI5d1PU1TWHZF-wGwOYqSn-uBtaCVifpzL3MQ0EStdFlrJ55~We-K11wYPl~noH~lrFxDs0YuiM~MmuJzZQewEiAIpPNlfyCox4wrTdpSlmTMBEb1ArmED~JpgLxe7V29OKQV~MrVKIog__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">the original</a>, I have made a number of changes to the code. Some of this is to meet my own styling preferences (similar to the <a href="https://style.tidyverse.org/">tidyverse style guide</a>), and some is just to reflect particularly programming practices that I try to encourage at my work. Here is a rough description of the changes I made:</p>

<ul>
  <li>Structure, sequencing and content
    <ul>
      <li>bring the definition of the data (number of shootings and the month they are in) up to the front and make a visualisation of it before we get into the analysis</li>
      <li>change the order of some of the analysis to match the presentation of results eg put the calculation of the likelihood ratio from pertured data ahead of the results from bootstrap resampling of the original</li>
    </ul>
  </li>
  <li>Discipline with objects and variables
    <ul>
      <li>with data that is intrinsically equal lengthed (such as the month and the year of each shooting - stored as vectors <code class="highlighter-rouge">mon</code> and <code class="highlighter-rouge">yr</code> in the original) store them in a data frame or tibble which provides the discipline of assuring that they are equally lengthed columns of data</li>
      <li>replace some magic constants (such as “13”, the number of massacres) with variables calculated by R (eg <code class="highlighter-rouge">n_massacres &lt;- nrow(mass_shootings)</code>, then use <code class="highlighter-rouge">n_massacres</code> instead of 13 from then onwards) - for maintainability and portability of the code to other use cases, and also for readability (it took me a while to spot the 13s in the code, whereas I find <code class="highlighter-rouge">n_massacres</code> very readable)</li>
      <li>change <code class="highlighter-rouge">T</code> and <code class="highlighter-rouge">F</code> to <code class="highlighter-rouge">TRUE</code> and <code class="highlighter-rouge">FALSE</code> throughout</li>
    </ul>
  </li>
  <li>Documentation, readability and style
    <ul>
      <li>add section and subsection markers</li>
      <li>more comments explaining the “why” of each step</li>
      <li>document the purpose and parameters of functions with “roxygen2 - style” (eg <code class="highlighter-rouge">@param</code>)</li>
      <li>spaces after commas, arithmetic operators, assignment operators etc - just for readability</li>
      <li>replace dots in variable names with underscores</li>
    </ul>
  </li>
</ul>

<h2 id="addendum">Addendum</h2>

<p>After original posting, my attention was drawn to the <a href="https://en.wikipedia.org/wiki/Osmington_shooting">Osmington shooting</a>, which happened after the period covered by the data in the original article (but before I moved back to Australia). This doesn’t change any of the analysis above of course, although it shows the importance of that robustness check of “one more massacre while the article is going into production”.</p>

<p>Here is the headline graphic of this post if this later event is included:</p>

<object type="image/svg+xml" data="/img/0158-events-with-osmington.svg" width="100%"><img src="/img/0158-events-with-osmington.png" /></object>

<h2 id="footnotes">Footnotes</h2>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Am I just dreaming that Tukey made some semi-humourous statement along these lines? I can’t find a reference. Comments welcomed. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>


		
	</div>
</div>

<div class="col-md-1"></div>
<div class="col-md-4">
	<div class="side-banner">
	


	<div>
	   
	    
			
			<p>&larr; Previous post</p>
			<p><a rel="prev" href="/blog/2019/08/25/fitting-bins">Inferring a continuous distribution from binned data</a></p>
		
		
		
		
		 
			
			<p>Next post &rarr;</p>
			<p><a rel="next" href="/blog/2019/11/03/re-creating-microdata">Re-creating survey microdata from marginal totals</a></p>
			
			
		
		
	</div>
	
	 

   <div class = "side-footer">
			
			<hr></hr>
			<p><gcse:search></gcse:search></p>
			<hr></hr>
        	<p>Follow <a href = "/feed.xml">this blog with RSS</a>.</p>
			<hr></hr>
			
       <div class="fb-like" data-href="https://www.facebook.com/peterstats/" data-layout="standard" data-action="like" data-show-faces="false" data-share="false"></div>
			
			<hr></hr>
			<p>I'm pleased to be aggregated at <a href="http://www.r-bloggers.com/">R-bloggers</a>, the one-stop shop for blog posts featuring R.</p>
			<hr></hr>

			
			<p>			
            <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><i>free range statistics</i></span> by <a href = "/about/index.html">Peter Ellis</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
			</p>

			<hr></hr>
			


    </div>



  
   




		  
		  



	   
	<div id="disqus_thread"></div>

		<script type="text/javascript">
			/* * * CONFIGURATION VARIABLES * * */
			var disqus_shortname = 'statsinthewild';
			
			/* * * DON'T EDIT BELOW THIS LINE * * */
			(function() {
				var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
				dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
				(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
			})();
		</script>

		<script type="text/javascript">
			/* * * CONFIGURATION VARIABLES * * */
			var disqus_shortname = 'statsinthewild';
			
			/* * * DON'T EDIT BELOW THIS LINE * * */
			(function () {
				var s = document.createElement('script'); s.async = true;
				s.type = 'text/javascript';
				s.src = '//' + disqus_shortname + '.disqus.com/count.js';
				(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
			}());
		</script>

	<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
	</div>	
</div>    
   
   

			
			</div><!-- /.container -->
         
   <!-- Default Statcounter code for Free Range Statistics
http://Http://freerangestats.info -->
<script type="text/javascript">
var sc_project=11673245; 
var sc_invisible=1; 
var sc_security="5b7111a4"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="http://statcounter.com/" target="_blank"><img class="statcounter"
src="//c.statcounter.com/11673245/0/5b7111a4/1/" alt="Web
Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->

</body>   
</html>